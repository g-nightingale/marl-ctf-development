{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from league_training import LeagueTrainer\n",
    "from scenarios import CtfScenarios as scn\n",
    "import torch\n",
    "\n",
    "# torch.set_num_threads(torch.get_num_threads())\n",
    "print(torch.get_num_threads())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig():\n",
    "    def __init__(self):\n",
    "        #---------- Overall config\n",
    "        self.wandb_project_name = \"MARL-CTF-Test\"\n",
    "        self.exp_name = \"2_jailbreak\"\n",
    "        self.use_wandb_selfplay = False\n",
    "        self.use_wandb_ppo = False\n",
    "        self.seed = 42\n",
    "        self.checkpoint_frequency = 10\n",
    "        self.number_of_metaruns = 1\n",
    "\n",
    "        #---------- Self-play config\n",
    "        self.number_of_iterations = 2\n",
    "        self.number_of_duels = 30\n",
    "        self.min_learning_rounds = 1\n",
    "        self.n_main_agents = 1\n",
    "        self.n_coaching_agents = 0\n",
    "        self.n_league_agents = 0\n",
    "        self.n_historical_agents = 0\n",
    "        self.min_agent_winrate = 0.4\n",
    "        self.min_historical_agent_winrate = 0.0\n",
    "        self.min_agent_winrate_for_promotion = 0.6\n",
    "        self.min_agent_iterations_for_replacement = 2\n",
    "        self.inference_interval = 1\n",
    "        self.historical_update_interval = 5\n",
    "\n",
    "        #---------- Environment config\n",
    "        self.env_config = {\n",
    "            'GRID_SIZE':11,\n",
    "            'AGENT_CONFIG':{\n",
    "                0: {'team':0, 'type':3},\n",
    "                1: {'team':1, 'type':0},\n",
    "                2: {'team':0, 'type':0},\n",
    "                3: {'team':1, 'type':0},\n",
    "                # 4: {'team':0, 'type':2},\n",
    "                # 5: {'team':1, 'type':2},\n",
    "            },\n",
    "            'SCENARIO': scn.jailbreak,\n",
    "            'GAME_STEPS': 500,\n",
    "            'USE_ADJUSTED_REWARDS': True,\n",
    "            'MAP_SYMMETRY_CHECK': False\n",
    "        }\n",
    "\n",
    "        #---------- PPO Config\n",
    "        self.n_actions = 9\n",
    "        self.learning_rate = 0.0003\n",
    "        self.total_timesteps = 12500\n",
    "        self.torch_deterministic = True\n",
    "        self.cuda = True\n",
    "        self.wandb_entity = None\n",
    "        self.parallel_rollouts = True\n",
    "        self.num_envs = 8\n",
    "        self.num_steps = 500\n",
    "        self.anneal_lr = False\n",
    "        self.gae = True\n",
    "        self.gamma = 0.999\n",
    "        self.gae_lambda = 0.95\n",
    "        self.num_minibatches = 4\n",
    "        self.update_epochs = 4\n",
    "        self.norm_adv = False\n",
    "        self.clip_coef = 0.2\n",
    "        self.clip_vloss = True\n",
    "        self.ent_coef = 0.01\n",
    "        self.vf_coef = 0.5\n",
    "        self.max_grad_norm = 0.5\n",
    "        self.target_kl = None\n",
    "        self.device = 'cpu'\n",
    "\n",
    "args = TrainingConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agents took 205.5004 seconds to run.\n",
      "\n",
      "Iteration: 1 Metrics collection...\n",
      "Total duels 30\n",
      "Metrics collection took 3.8180 seconds to run.\n",
      "\n",
      "Iteration: 1 Calculating win rate matrix...\n",
      "Calculating winrate matrix took 3.5809 seconds to run.\n",
      "\n",
      "Iteration: 1 updating agent pools...\n",
      "Updating agent pools took 0.0000 seconds to run.\n",
      "\n",
      "Saving objects...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ray_rollout pid=46334)\u001b[0m [W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 16min 11s\n",
    "league_trainer = LeagueTrainer(args)\n",
    "league_trainer.train_league()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1287ba8ead7066fc0830e0bd4af1d69cd835a22f57b43ce0ba097f5b2b7dfbb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
