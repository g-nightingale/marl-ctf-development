{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from league_training import LeagueTrainer\n",
    "from utils import duel, create_gif, create_plots, plot_heatmaps\n",
    "from scenarios import CtfScenarios as scn\n",
    "import torch\n",
    "\n",
    "# torch.set_num_threads(torch.get_num_threads())\n",
    "print(torch.get_num_threads())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfig():\n",
    "    def __init__(self):\n",
    "        #---------- Overall config\n",
    "        self.wandb_project_name = \"MARL-CTF-Test\"\n",
    "        self.exp_name = \"2_jailbreak\"\n",
    "        self.use_wandb_selfplay = False\n",
    "        self.use_wandb_ppo = False\n",
    "        self.seed = 42\n",
    "        self.checkpoint_frequency = 10\n",
    "        self.number_of_metaruns = 3\n",
    "\n",
    "        #---------- Self-play config\n",
    "        self.number_of_iterations = 20\n",
    "        self.number_of_duels = 30\n",
    "        self.min_learning_rounds = 1\n",
    "        self.n_main_agents = 1\n",
    "        self.n_coaching_agents = 0\n",
    "        self.n_league_agents = 0\n",
    "        self.n_historical_agents = 0\n",
    "        self.min_agent_winrate = 0.4\n",
    "        self.min_historical_agent_winrate = 0.0\n",
    "        self.min_agent_winrate_for_promotion = 0.6\n",
    "        self.min_agent_iterations_for_replacement = 2\n",
    "        self.inference_interval = 1\n",
    "        self.historical_update_interval = 5\n",
    "\n",
    "        #---------- Environment config\n",
    "        self.env_config = {\n",
    "            'GRID_SIZE':11,\n",
    "            'AGENT_CONFIG':{\n",
    "                0: {'team':0, 'type':3},\n",
    "                1: {'team':1, 'type':0},\n",
    "                2: {'team':0, 'type':0},\n",
    "                3: {'team':1, 'type':0},\n",
    "                # 4: {'team':0, 'type':2},\n",
    "                # 5: {'team':1, 'type':2},\n",
    "            },\n",
    "            'SCENARIO': scn.jailbreak,\n",
    "            'GAME_STEPS': 500,\n",
    "            'USE_ADJUSTED_REWARDS': True,\n",
    "            'MAP_SYMMETRY_CHECK': False\n",
    "        }\n",
    "\n",
    "        #---------- PPO Config\n",
    "        self.n_actions = 9\n",
    "        self.learning_rate = 0.0003\n",
    "        self.total_timesteps = 12500\n",
    "        self.torch_deterministic = True\n",
    "        self.cuda = True\n",
    "        self.wandb_entity = None\n",
    "        self.parallel_rollouts = True\n",
    "        self.num_envs = 8\n",
    "        self.num_steps = 500\n",
    "        self.anneal_lr = False\n",
    "        self.gae = True\n",
    "        self.gamma = 0.999\n",
    "        self.gae_lambda = 0.95\n",
    "        self.num_minibatches = 4\n",
    "        self.update_epochs = 4\n",
    "        self.norm_adv = False\n",
    "        self.clip_coef = 0.2\n",
    "        self.clip_vloss = True\n",
    "        self.ent_coef = 0.01\n",
    "        self.vf_coef = 0.5\n",
    "        self.max_grad_norm = 0.5\n",
    "        self.target_kl = None\n",
    "        self.device = 'cpu'\n",
    "\n",
    "args = TrainingConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 10:44:45,356\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Training agents...\n",
      "Teams are not symmetric - two leagues will be trained\n",
      "Iteration: 0 Team: 0 Training main agent 0 vs main agent 0\n",
      "Batch size: 8000\n",
      "Minibatch size: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ray_rollout pid=31545)\u001b[0m [W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
      "[W NNPACK.cpp:64] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 1\t steps: 4000\t ar: 0.00\t mx: 0.0\t lr: 0.0003\t vl: 0.0\t pl: 0.0023\t ent: 1.8926\t\n",
      "i: 2\t steps: 8000\t ar: 0.03\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0022\t pl: 0.0015\t ent: 1.9149\t\n",
      "i: 3\t steps: 12000\t ar: -0.02\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0014\t pl: 0.002\t ent: 1.8938\t\n",
      "i: 4\t steps: 16000\t ar: -0.07\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0024\t pl: 0.0053\t ent: 1.9079\t\n",
      "i: 5\t steps: 20000\t ar: -0.10\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0018\t pl: 0.0062\t ent: 1.8899\t\n",
      "i: 6\t steps: 24000\t ar: -0.07\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0018\t pl: -0.0005\t ent: 1.902\t\n",
      "i: 7\t steps: 28000\t ar: -0.16\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0015\t pl: 0.0104\t ent: 1.8975\t\n",
      "i: 8\t steps: 32000\t ar: -0.14\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0001\t pl: 0.0023\t ent: 1.9075\t\n",
      "i: 9\t steps: 36000\t ar: -0.14\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0011\t pl: 0.0078\t ent: 1.9002\t\n",
      "i: 10\t steps: 40000\t ar: -0.14\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.001\t pl: 0.0068\t ent: 1.8989\t\n",
      "i: 11\t steps: 44000\t ar: -0.22\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0018\t pl: 0.0063\t ent: 1.8963\t\n",
      "i: 12\t steps: 48000\t ar: -0.11\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0012\t pl: -0.0002\t ent: 1.8982\t\n",
      "i: 13\t steps: 52000\t ar: -0.16\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0011\t pl: 0.0062\t ent: 1.9053\t\n",
      "i: 14\t steps: 56000\t ar: -0.13\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0014\t pl: 0.005\t ent: 1.8992\t\n",
      "i: 15\t steps: 60000\t ar: -0.07\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0014\t pl: 0.0016\t ent: 1.9081\t\n",
      "i: 16\t steps: 64000\t ar: 0.00\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0008\t pl: -0.0043\t ent: 1.9055\t\n",
      "i: 17\t steps: 68000\t ar: -0.11\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0011\t pl: 0.0077\t ent: 1.888\t\n",
      "i: 18\t steps: 72000\t ar: -0.10\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0017\t pl: 0.0034\t ent: 1.9043\t\n",
      "i: 19\t steps: 76000\t ar: -0.08\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0008\t pl: -0.0005\t ent: 1.9005\t\n",
      "i: 20\t steps: 80000\t ar: -0.13\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0009\t pl: 0.0039\t ent: 1.9036\t\n",
      "i: 21\t steps: 84000\t ar: -0.13\t mx: 1.2000000476837158\t lr: 0.0003\t vl: 0.0008\t pl: -0.0032\t ent: 1.8942\t\n"
     ]
    }
   ],
   "source": [
    "# 16min 11s\n",
    "league_trainer = LeagueTrainer(args)\n",
    "league_trainer.train_league()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1287ba8ead7066fc0830e0bd4af1d69cd835a22f57b43ce0ba097f5b2b7dfbb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
